{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b68baf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kezhang/work/stochastic-critic/.venv/lib/python3.10/site-packages/Cython/Distutils/old_build_ext.py:15: DeprecationWarning: dep_util is Deprecated. Use functions from setuptools instead.\n",
      "  from distutils.dep_util import newer, newer_group\n",
      "<frozen importlib._bootstrap>:283: DeprecationWarning: the load_module() method is deprecated and slated for removal in Python 3.12; use exec_module() instead\n",
      "Warning: Flow failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.\n",
      "No module named 'flow'\n",
      "/home/kezhang/work/stochastic-critic/.venv/lib/python3.10/site-packages/glfw/__init__.py:914: GLFWError: (65544) b'X11: The DISPLAY environment variable is missing'\n",
      "  warnings.warn(message, GLFWError)\n",
      "Warning: CARLA failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.\n",
      "No module named 'carla'\n",
      "pybullet build time: Nov 28 2023 23:45:17\n",
      "/home/kezhang/work/stochastic-critic/.venv/lib/python3.10/site-packages/pybullet_envs/env_bases.py:8: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  from pkg_resources import parse_version\n",
      "/home/kezhang/work/stochastic-critic/.venv/lib/python3.10/site-packages/pkg_resources/__init__.py:2976: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(pkg)\n"
     ]
    }
   ],
   "source": [
    "import d4rl\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import gym\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from model import Resnet, EBMDiffusionModel\n",
    "from diffusion import DiffusionModel\n",
    "from data_sampler import DataSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79ddd9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdd5fe58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kezhang/work/stochastic-critic/.venv/lib/python3.10/site-packages/gym/spaces/box.py:84: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "load datafile: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 13.36it/s]\n"
     ]
    }
   ],
   "source": [
    "env_name = 'halfcheetah-medium-v2'\n",
    "env = gym.make(env_name)\n",
    "\n",
    "dataset = d4rl.qlearning_dataset(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1111159c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sampler = DataSampler(dataset, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2274f56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = data_sampler.sample(keys=[\"observations\", \"actions\"], batch_size=1, concat=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0c459b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0645, -0.1249, -0.0300,  0.2821, -0.2713, -0.4986, -0.1250, -0.2375,\n",
       "          4.9944,  0.6616, -1.7421, -0.2686,  2.4481, -1.1449, 15.4297, -3.2255,\n",
       "          2.1888, -0.9741, -0.9833, -0.9910, -0.4961, -0.9770,  0.8868]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c71c33bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "data_dim = sample.shape[-1]\n",
    "\n",
    "EMA = .999\n",
    "\n",
    "n_steps = 100\n",
    "net_params = {\"n_layers\": 4,\n",
    "              \"h_dim\": 128,\n",
    "              \"emb_dim\": 32}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01ede7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xr = [-.75, .75]\n",
    "# yr = [-.75, .75]\n",
    "\n",
    "# # load data\n",
    "# dataset_energy, dataset_sample = toy_gmm(std=.03)\n",
    "# x = dataset_sample(batch_size)\n",
    "\n",
    "# plot_samples(x)\n",
    "# plt.show()\n",
    "# x = x.reshape(x.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f861b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Resnet(n_steps=n_steps, n_layers=4, x_dim=data_dim, h_dim=128, emb_dim=32)\n",
    "\n",
    "ebm_net = EBMDiffusionModel(net)\n",
    "\n",
    "ddpm = DiffusionModel(data_dim, n_steps, ebm_net, device=device, var_type=\"beta_forward\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64d2a329",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logp_unnorm(net, ddpm, x, t):\n",
    "    scale_e = ddpm.energy_scale(-2 - t)\n",
    "    t = torch.ones((x.shape[0],)).int() * t\n",
    "    return -net.neg_logp_unnorm(x, t) * scale_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da52faab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DiffusionModel(\n",
       "  (net): EBMDiffusionModel(\n",
       "    (net): Resnet(\n",
       "      (layer_x): Linear(in_features=23, out_features=128, bias=True)\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x Sequential(\n",
       "          (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (1): Linear(in_features=32, out_features=256, bias=True)\n",
       "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (last_layer): Linear(in_features=128, out_features=23, bias=True)\n",
       "      (time_emb): Embedding(100, 32)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0039974b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(30.7890, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>) time: 0.4993598461151123\n",
      "tensor([[-0.2572, -0.2860,  0.1034,  0.0638,  0.1779,  0.0331,  0.0363,  0.0224,\n",
      "          0.0909, -0.1637,  0.0379, -0.0761, -0.0349,  0.2749,  0.0080,  0.6047,\n",
      "         -0.0560,  0.1470,  0.2150, -0.1010,  0.2330,  0.1326,  0.0382]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "100 tensor(0.5459, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>) time: 0.006296634674072266\n",
      "200 tensor(0.4913, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>) time: 0.006285190582275391\n",
      "300 tensor(0.4672, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>) time: 0.0062103271484375\n",
      "400 tensor(0.4534, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>) time: 0.006283998489379883\n",
      "500 tensor(0.4574, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>) time: 0.006414175033569336\n",
      "600 tensor(0.4325, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>) time: 0.0062732696533203125\n",
      "700 tensor(0.4436, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>) time: 0.006416797637939453\n",
      "800 tensor(0.4448, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>) time: 0.006396770477294922\n",
      "900 tensor(0.4199, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>) time: 0.006305694580078125\n",
      "1000 tensor(0.4136, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>) time: 0.010562658309936523\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m itr \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     30\u001b[0m     ddpm\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m---> 31\u001b[0m     x_samp \u001b[38;5;241m=\u001b[39m \u001b[43mddpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(x_samp)\n",
      "File \u001b[0;32m~/work/fall_2024/energy-based-diffusion-model/diffusion.py:220\u001b[0m, in \u001b[0;36mDiffusionModel.sample\u001b[0;34m(self, n, clip)\u001b[0m\n\u001b[1;32m    218\u001b[0m   j \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_steps \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m i\n\u001b[1;32m    219\u001b[0m   t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones((n,), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint64)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;241m*\u001b[39m j\n\u001b[0;32m--> 220\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclip\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/work/fall_2024/energy-based-diffusion-model/diffusion.py:185\u001b[0m, in \u001b[0;36mDiffusionModel.p_sample\u001b[0;34m(self, x, t, rng_key, clip)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mp_sample\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, t, rng_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, clip\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39minf):\n\u001b[1;32m    183\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Sample from p(x_{t-1} | x_t).\"\"\"\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m   mean, _, log_var \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp_mean_variance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclip\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m   noise \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(size\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mshape))\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    189\u001b[0m   x_tm1 \u001b[38;5;241m=\u001b[39m mean \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m log_var) \u001b[38;5;241m*\u001b[39m noise\n",
      "File \u001b[0;32m~/work/fall_2024/energy-based-diffusion-model/diffusion.py:166\u001b[0m, in \u001b[0;36mDiffusionModel.p_mean_variance\u001b[0;34m(self, x, t, clip)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mp_mean_variance\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, t, clip\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39minf):\n\u001b[1;32m    163\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Parameters of p(x_{t-1} | x_t).\"\"\"\u001b[39;00m\n\u001b[1;32m    165\u001b[0m   x_recon \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclip(\n\u001b[0;32m--> 166\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_start_from_noise(x, t, noise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m), \u001b[38;5;241m-\u001b[39mclip,\n\u001b[1;32m    167\u001b[0m       clip)\n\u001b[1;32m    169\u001b[0m   mean, var, log_var \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_posterior(x_recon, x, t)\n\u001b[1;32m    172\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_var_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbeta_reverse\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/work/fall_2024/energy-based-diffusion-model/diffusion.py:75\u001b[0m, in \u001b[0;36mDiffusionModel.forward\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     71\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39matleast_2d(x)\n\u001b[1;32m     72\u001b[0m t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39matleast_1d(t)\n\u001b[0;32m---> 75\u001b[0m outs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outs\n",
      "File \u001b[0;32m~/work/fall_2024/energy-based-diffusion-model/model.py:93\u001b[0m, in \u001b[0;36mEBMDiffusionModel.__call__\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, t):\n\u001b[1;32m     92\u001b[0m     neg_logp_unnorm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m _x: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneg_logp_unnorm(_x, t)\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneg_logp_unnorm\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/stochastic-critic/.venv/lib/python3.10/site-packages/torch/_functorch/apis.py:397\u001b[0m, in \u001b[0;36mgrad.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43meager_transforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margnums\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_aux\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/stochastic-critic/.venv/lib/python3.10/site-packages/torch/_functorch/eager_transforms.py:1451\u001b[0m, in \u001b[0;36mgrad_impl\u001b[0;34m(func, argnums, has_aux, args, kwargs)\u001b[0m\n\u001b[1;32m   1450\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrad_impl\u001b[39m(func: Callable, argnums: argnums_t, has_aux: \u001b[38;5;28mbool\u001b[39m, args, kwargs):\n\u001b[0;32m-> 1451\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mgrad_and_value_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margnums\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_aux\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1452\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_aux:\n\u001b[1;32m   1453\u001b[0m         grad, (_, aux) \u001b[38;5;241m=\u001b[39m results\n",
      "File \u001b[0;32m~/work/stochastic-critic/.venv/lib/python3.10/site-packages/torch/_functorch/vmap.py:48\u001b[0m, in \u001b[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mdisable_saved_tensors_hooks(message):\n\u001b[0;32m---> 48\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/stochastic-critic/.venv/lib/python3.10/site-packages/torch/_functorch/eager_transforms.py:1435\u001b[0m, in \u001b[0;36mgrad_and_value_impl\u001b[0;34m(func, argnums, has_aux, args, kwargs)\u001b[0m\n\u001b[1;32m   1433\u001b[0m \u001b[38;5;66;03m# NB: need create_graph so that backward pass isn't run in no_grad mode\u001b[39;00m\n\u001b[1;32m   1434\u001b[0m flat_outputs \u001b[38;5;241m=\u001b[39m _as_tuple(output)\n\u001b[0;32m-> 1435\u001b[0m flat_grad_input \u001b[38;5;241m=\u001b[39m \u001b[43m_autograd_grad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1436\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_diff_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m   1437\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1438\u001b[0m grad_input \u001b[38;5;241m=\u001b[39m tree_unflatten(flat_grad_input, spec)\n\u001b[1;32m   1440\u001b[0m grad_input \u001b[38;5;241m=\u001b[39m _undo_create_differentiable(grad_input, level)\n",
      "File \u001b[0;32m~/work/stochastic-critic/.venv/lib/python3.10/site-packages/torch/_functorch/eager_transforms.py:181\u001b[0m, in \u001b[0;36m_autograd_grad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(diff_outputs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(torch\u001b[38;5;241m.\u001b[39mzeros_like(inp) \u001b[38;5;28;01mfor\u001b[39;00m inp \u001b[38;5;129;01min\u001b[39;00m inputs)\n\u001b[0;32m--> 181\u001b[0m grad_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdiff_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m grad_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m    190\u001b[0m     torch\u001b[38;5;241m.\u001b[39mzeros_like(inp) \u001b[38;5;28;01mif\u001b[39;00m gi \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m gi\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m gi, inp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(grad_inputs, inputs)\n\u001b[1;32m    192\u001b[0m )\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grad_inputs\n",
      "File \u001b[0;32m~/work/stochastic-critic/.venv/lib/python3.10/site-packages/torch/autograd/__init__.py:436\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[1;32m    432\u001b[0m     result \u001b[38;5;241m=\u001b[39m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(\n\u001b[1;32m    433\u001b[0m         grad_outputs_\n\u001b[1;32m    434\u001b[0m     )\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 436\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m materialize_grads:\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    447\u001b[0m         result[i] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor_like(inputs[i])\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs))\n\u001b[1;32m    449\u001b[0m     ):\n",
      "File \u001b[0;32m~/work/stochastic-critic/.venv/lib/python3.10/site-packages/torch/autograd/graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "test_logpx = []\n",
    "itr = 0\n",
    "\n",
    "ddpm.train()\n",
    "optimizer = torch.optim.Adam(ddpm.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "num_steps = 200000\n",
    "for itr in range(num_steps):\n",
    "    ddpm.train()\n",
    "    \n",
    "    x = data_sampler.sample(keys=[\"observations\", \"actions\"], batch_size=batch_size, concat=True)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    loss = ddpm.loss(x)\n",
    "    loss = loss.mean()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    duration_update = time.time() - start_time\n",
    "\n",
    "    if itr % 100 == 0:\n",
    "        print(itr, loss, \"time:\", duration_update)\n",
    "        losses.append(loss)\n",
    "        \n",
    "    if itr % 1000 == 0:\n",
    "        ddpm.eval()\n",
    "        x_samp = ddpm.sample(n=1)\n",
    "        print(x_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c868c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stochastic-critic",
   "language": "python",
   "name": "stochastic-critic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
